
## Complexity

... most saliently: **time** and **space** complexity.

!!! -

Consider this benchmark run:


:::center

| Name (time in ms)               | Min              | Max              | Mean             |
|---------------------------------|------------------|------------------|------------------|
| test_python_mm[A0-B0-R0]        | 16.1899 (1.0)    | 19.8583 (1.0)    | 17.1774 (1.0)    |
| test_python_mm[A1-B1-R1]        | 132.7527 (8.20)  | 141.1280 (7.11)  | 136.3944 (7.94)  |
| test_python_mm[A2-B2-R2]        | 429.3815 (26.52) | 468.6134 (23.60) | 444.4869 (25.88) |
| test_python_mm[A3-B3-R3]        | 1,014.5279 (62.66)| 1,083.2412 (54.55)| 1,040.5810 (60.58)|
| test_python_mm[A4-B4-R4]        | 1,983.5240 (122.52)| 2,130.7804 (107.30)| 2,037.3249 (118.61)|

:::

:::center
```
A0-B0-R0 .... 10x10
A1-B1-R1 .... 20x20
A2-B2-R2 .... 30x30
A3-B3-R3 .... 40x40
A4-B4-R4 .... 50x50
```
:::

!!! note
    These are five tests benchmarking the simple square matrix multiplication python function.
        
    The functions only differ in the size of the input matrices. 10x10, 20x20, 30x30 and so on.
    Some simple curve fitting reveals that the function has approx. **O(n^3)** time complexity where **n** is the size of **one side** of the matrix.
    This makes perfect sense when we look at the code for the function in question:

```py
def multiply_matrix_python(A: npt.NDArray, B: npt.NDArray):
    a_rows, a_cols = A.shape
    b_rows, b_cols = B.shape

    # iffy sanity checks
    if a_rows != b_rows or a_cols != b_cols:
        return False

    # allocate result memory
    result = np.zeros((a_rows, b_cols))

    # do actual work
    # using the renowned "Schoolbook algorithm"
    for row in range(a_rows):
        for col in range(b_cols):
            for elt in range(a_rows):
                result[row, col] = result[row, col] + A[row, elt] * B[elt, col]

    return result

```

**O(n^3)** time complexity where **n** is the size of **one side** of the matrix.

!!! note
    As you can see we have three nested loops all iterating over the size of the matrix. Resulting in size^3 multiplications.

    Simply put with this notation we can describe a relationship between some characteristics of the input data ("n") and the run time of an algorithm ("O(n)").

```py
def get_middle_item(items: list):
    return items[len(items) // 2]
```

!!! -

has **O(1)** time-complexity, at least as long as `len(items)` has **O(1)** tc.

!!! note
    There is a full list of python builtin time complexities on the wiki.

```py
def sum_items(items: list[int]):
    sum_ = 0
    for item in items:
        sum_ += item
    return sum_
```

!!! -

has **O(n)** time-complexity.

!!! note

```py
def partition(items: list[int], low: int, high: int):
    pivot = items[high]
    i = low - 1
    for j in range(low, high):
        if items[j] <= pivot:
            i = i + 1
            (items[i], items[j]) = (items[j], items[i])
    (items[i + 1], items[high]) = (items[high], items[i + 1])
    return i + 1

def quick_sort(
    items: list[int], 
    low: int | None = None, 
    high: int | None = None
):
    if low is None or high is None:
        low = 0
        high = len(items)
    
    if low < high:
        pi = partition(items, low, high)
        quick_sort(items, low, pi - 1)
        quick_sort(items, pi + 1, high)
```

!!! -

Quick sort has a *average* **O(n * log(n))** time-complexity.

!!! note
    Worst case: **O(n^2)**, Best case: still **O(n * log(n))** 

    Apparently there is a special version of quick sort that hase a best case **O(n)** performance.


!!! -

This is where it gets a little bit tricky... Lets consider a simple list search:

```py
def search(
    items: list[int], 
    query: int,
) -> int | None:
    for index, value in enumerate(items):
        if value == query:
            return i
    return None
```

!!! -

Worst Case: **O(n)**

!!! -

Best Case: **Ω(1)**

!!! -

Average Case: **θ(n)**

!!! -

The average case depends on our **"average" input data**. If list items are **unique**, **completely random** and **the query items always exists** the average time complexity will still be **θ(n)**, since the "average" item we are looking for will be in the middle.

!!! note
    Obviously the average dataset will still be about 2x faster than the worst case dataset.


Often **worst**, **best** and **average**  case complexities are denoted with **O** ("O"), **Ω** (omega), **θ** (theta).

!!! note
    Call the notation police, I dare you.

### Common Time Complexities

| Big O Notation   | Name         | Example(s)                                                                    |
|------------------|--------------|-------------------------------------------------------------------------------|
| **O(1)**         | Constant     | Odd or Even number, Look-up table                                             |
| **O(log n)**     | Logarithmic  | Binary-search, generally binary trees should smell like `log`                 |
| **O(n)**         | Linear       | Find max element in unsorted array, Duplicate elements in array with Hash Map |
| **O(n log n)**   | Linearithmic | Merge sort, Quick sort, generally a lot of sorting algorithms                 |
| **O(n²)**        | Quadratic    | Sorting array with bubble sort                                                |
| **O(n³)**        | Cubic        | Schoolbook square matrix mult., 3 variables equation solver                   |
| **O(2ⁿ)**        | Exponential  | Find all subsets (the pizza topping problem)                                  |
| **O(n!)**        | Factorial    | Brute-Force a Password (all permutations, no rainbow tables), Bogosort (n*n!) |
|------------------|--------------|-------------------------------------------------------------------------------|

!!! note
    Here are some of the most common time complexities and some example algorithms.


```bash
pytest -k test_tc_get_middle_item -q --benchmark-histogram --benchmark-autosave
pytest -k test_tc_sum_items -q --benchmark-histogram --benchmark-autosave
pytest -k test_tc_sum_builtin -q --benchmark-histogram --benchmark-autosave
pytest -k test_tc_quick_sort -q --benchmark-histogram --benchmark-autosave
pytest -k test_tc_sorted_builtin -q --benchmark-histogram --benchmark-autosave
```

!!! note
    Run the benchmarks with theses commands.

---

- Wikipedia: [Big O Notation](https://en.wikipedia.org/wiki/Big_O_notation)
- Python Wiki: [Time Complexity](https://wiki.python.org/moin/TimeComplexity)
- Wikipedia: [Quick sort](https://en.wikipedia.org/wiki/Quicksort)

!!! links
